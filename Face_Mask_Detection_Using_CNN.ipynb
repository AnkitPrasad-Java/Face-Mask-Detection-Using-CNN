{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyNy9Ldc1hRit/yGVGpV1HoI",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/AnkitPrasad-Java/Face-Mask-Detection-Using-CNN/blob/main/Face_Mask_Detection_Using_CNN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install kaggle"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SgzC-bUtbsCI",
        "outputId": "72134f55-d5aa-4cc9-e990-d6a32de1d76f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: kaggle in /usr/local/lib/python3.12/dist-packages (1.7.4.5)\n",
            "Requirement already satisfied: bleach in /usr/local/lib/python3.12/dist-packages (from kaggle) (6.2.0)\n",
            "Requirement already satisfied: certifi>=14.05.14 in /usr/local/lib/python3.12/dist-packages (from kaggle) (2025.8.3)\n",
            "Requirement already satisfied: charset-normalizer in /usr/local/lib/python3.12/dist-packages (from kaggle) (3.4.3)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.12/dist-packages (from kaggle) (3.10)\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.12/dist-packages (from kaggle) (5.29.5)\n",
            "Requirement already satisfied: python-dateutil>=2.5.3 in /usr/local/lib/python3.12/dist-packages (from kaggle) (2.9.0.post0)\n",
            "Requirement already satisfied: python-slugify in /usr/local/lib/python3.12/dist-packages (from kaggle) (8.0.4)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from kaggle) (2.32.4)\n",
            "Requirement already satisfied: setuptools>=21.0.0 in /usr/local/lib/python3.12/dist-packages (from kaggle) (75.2.0)\n",
            "Requirement already satisfied: six>=1.10 in /usr/local/lib/python3.12/dist-packages (from kaggle) (1.17.0)\n",
            "Requirement already satisfied: text-unidecode in /usr/local/lib/python3.12/dist-packages (from kaggle) (1.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (from kaggle) (4.67.1)\n",
            "Requirement already satisfied: urllib3>=1.15.1 in /usr/local/lib/python3.12/dist-packages (from kaggle) (2.5.0)\n",
            "Requirement already satisfied: webencodings in /usr/local/lib/python3.12/dist-packages (from kaggle) (0.5.1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#configuring the path of Kaggle.json file\n",
        "!mkdir -p ~/.kaggle\n",
        "!cp kaggle.json ~/.kaggle/\n",
        "!chmod 600 ~/.kaggle/kaggle.json"
      ],
      "metadata": {
        "id": "Ox9cU8BobuSl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Importing the Dataset"
      ],
      "metadata": {
        "id": "qXPsEv59edmq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import kagglehub\n",
        "\n",
        "# Download latest version\n",
        "path = kagglehub.dataset_download(\"omkargurav/face-mask-dataset\")\n",
        "\n",
        "print(\"Path to dataset files:\", path)"
      ],
      "metadata": {
        "id": "H7AmxnaCecKt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# to list your directory\n",
        "!ls"
      ],
      "metadata": {
        "id": "lLHOd-eze6LD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Importing the dependencies**"
      ],
      "metadata": {
        "id": "-OHJc6bwgF09"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.image as mpimg\n",
        "import cv2 # Image processing\n",
        "from google.colab.patches import cv2_imshow #\n",
        "from PIL import Image # PIL is used for image processing\n",
        "from sklearn.model_selection import train_test_split #It is used to split our data"
      ],
      "metadata": {
        "id": "yea_z0-GgBRi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with_mask_files=os.listdir('/kaggle/input/face-mask-dataset/data/with_mask')\n",
        "print(with_mask_files[0:5]) # First Five Columns\n",
        "print(with_mask_files[-5:]) # Last Five Columns"
      ],
      "metadata": {
        "id": "hlStnXK9kHH_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "without_mask_files=os.listdir('/kaggle/input/face-mask-dataset/data/without_mask')\n",
        "print(without_mask_files[0:5]) # First Five Columns\n",
        "print(without_mask_files[-5:]) # Last Five Columns"
      ],
      "metadata": {
        "id": "BMSPGKUbkzf-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print('Number of with masks images', len(with_mask_files))\n",
        "print('Number of without masks images', len(without_mask_files))"
      ],
      "metadata": {
        "id": "XyemT3IOl8p4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We will create a label for 'with mask' and 'without mask' images.\n",
        "\n",
        "**Note- It is easier to create labels in our case because we have segregated data but it is true that we will not have segregated data everytime. At those times you will have to read individual file name and then label it accordingly.**"
      ],
      "metadata": {
        "id": "ham1sN3QmfHj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Creating Labels for the two class of images**"
      ],
      "metadata": {
        "id": "BpgdhFwunLJP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "With Mask --> 1\n",
        "\n",
        "Without Mask --> 0"
      ],
      "metadata": {
        "id": "wRMST1MYnP43"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# create the labels\n",
        "\n",
        "with_mask_labels =[1]*3725\n",
        "without_mask_labels=[0]*3828"
      ],
      "metadata": {
        "id": "_B4rvHDXnaM_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(with_mask_labels[0:5])\n",
        "print(without_mask_labels[0:5])"
      ],
      "metadata": {
        "id": "WJiokygPnzD7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "  print(len(with_mask_labels))\n",
        "  print(len(without_mask_labels))"
      ],
      "metadata": {
        "id": "JcIk30HLn7H4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "labels= with_mask_labels + without_mask_labels\n",
        "\n",
        "print(len(labels))\n",
        "print(labels[0:5])\n",
        "print(labels[-5:])"
      ],
      "metadata": {
        "id": "N39sFmgaoFZs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Displaying the images**"
      ],
      "metadata": {
        "id": "Zw03tI2SpBzB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# displaying with_mask image\n",
        "img=mpimg.imread('/kaggle/input/face-mask-dataset/data/with_mask/with_mask_696.jpg')\n",
        "imgplot=plt.imshow(img)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "-5Hdsg9doWaG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# displaying with_mask image\n",
        "img=mpimg.imread('/kaggle/input/face-mask-dataset/data/with_mask/with_mask_2867.jpg')\n",
        "imgplot=plt.imshow(img)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "rtufA_YNpvLe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# displaying without_mask image\n",
        "img=mpimg.imread('/kaggle/input/face-mask-dataset/data/without_mask/without_mask_3215.jpg')\n",
        "imgplot=plt.imshow(img)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "jCwtLgYcqTBB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# displaying without_mask image\n",
        "img=mpimg.imread('/kaggle/input/face-mask-dataset/data/without_mask/without_mask_2925.jpg')\n",
        "imgplot=plt.imshow(img)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "Iu15olHJqmj2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Image Processing**"
      ],
      "metadata": {
        "id": "17z-Eyb6q2JF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1) Resize the images.\n",
        "\n",
        "2) Convert the images to numpy arrays."
      ],
      "metadata": {
        "id": "hh8abpRPq_W0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# convert masked images to numpy arrays\n",
        "\n",
        "with_mask_path = '/kaggle/input/face-mask-dataset/data/with_mask/' # we need to put a forward slash at the end because we need to\n",
        "\n",
        "data=[]\n",
        "\n",
        "for img_file in with_mask_files:\n",
        "\n",
        "  image=Image.open(with_mask_path + img_file) # I want to read each image with masks(Image is from PIL library and img_file will read the first image in with_mask file)\n",
        "  image=image.resize((128,128)) # resizing the image\n",
        "  image=image.convert('RGB') # There are some images which are black and white\n",
        "  image=np.array(image)\n",
        "  data.append(image)\n",
        "\n",
        "\n",
        "# convert without mask images to numpy arrays\n",
        "\n",
        "without_mask_path = '/kaggle/input/face-mask-dataset/data/without_mask/' # we need to put a forward slash at the end because we need to\n",
        "\n",
        "for img_file in without_mask_files:\n",
        "\n",
        "  image=Image.open(without_mask_path + img_file) # I want to read each image with masks(Image is from PIL library and img_file will read the first image in with_mask file)\n",
        "  image=image.resize((128,128)) # resizing the image\n",
        "  image=image.convert('RGB') # There are some images which are black and white\n",
        "  image=np.array(image)\n",
        "  data.append(image)\n"
      ],
      "metadata": {
        "id": "_JEjVqA-qtn7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "type(data)"
      ],
      "metadata": {
        "id": "aoJfntnUjQmQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(data)"
      ],
      "metadata": {
        "id": "FiTQrvYEmcN3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data[0]"
      ],
      "metadata": {
        "id": "JZzO3-gMmd_G"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "type(data[0])"
      ],
      "metadata": {
        "id": "KIFip4mjmiAL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data[0].shape"
      ],
      "metadata": {
        "id": "rNK7uZA3msqo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# converting image list and label list to numpy array\n",
        "\n",
        "X=np.array(data)\n",
        "Y=np.array(labels)"
      ],
      "metadata": {
        "id": "y7bsRHZNmurO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "type(X)"
      ],
      "metadata": {
        "id": "cApuZNLOocP5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "type(Y)"
      ],
      "metadata": {
        "id": "o5YT0ZPTolIf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(X.shape)\n",
        "print(Y.shape)"
      ],
      "metadata": {
        "id": "aNvirdqJonUB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(Y)"
      ],
      "metadata": {
        "id": "FSCpplfGospC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Train and Test split**"
      ],
      "metadata": {
        "id": "ipokyS71o5GX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2, random_state=2) # @20% of data is testing data"
      ],
      "metadata": {
        "id": "sAPCAs07o30X"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(X.shape, X_train.shape, X_test.shape)"
      ],
      "metadata": {
        "id": "X_nbT_0rpW2H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# scaling the data\n",
        "\n",
        "X_train_scaled= X_train/255\n",
        "\n",
        "X_test_scaled= X_test/255\n",
        "\n",
        "# we did this to change the data array values between 0 and 1."
      ],
      "metadata": {
        "id": "ipEN5A7xpdt9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train[0]"
      ],
      "metadata": {
        "id": "9RJH_99Cpzew"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train_scaled[0]"
      ],
      "metadata": {
        "id": "n05OcECNraD4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Buliding a Convolutional Neural Network(CNN)**"
      ],
      "metadata": {
        "id": "ab_-ciiirmoJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras"
      ],
      "metadata": {
        "id": "-EYaNJeJrdRB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "num_of_classes=2 # with mask and without mask\n",
        "\n",
        "model=keras.Sequential() # where we stack all our layers\n",
        "\n",
        "model.add(keras.layers.Conv2D(32, kernel_size=(3,3), activation='relu', input_shape=(128,128,3))) # It applies 32 convolution filters, each of size 3x3.\n",
        "model.add(keras.layers.MaxPooling2D(pool_size=(2,2)))\n",
        "\n",
        "model.add(keras.layers.Conv2D(64, kernel_size=(3,3), activation='relu')) # same as above but with 64 filters\n",
        "model.add(keras.layers.MaxPooling2D(pool_size=(2,2))) # Reduces spatial dimensions (width & height) by taking the maximum value in each 2Ã—2 block.\n",
        "\n",
        "model.add(keras.layers.Flatten()) # while passing your data or image to your model, as the numpy array is shown as an array. It converts smthng to a type of vector.\n",
        "\n",
        "model.add(keras.layers.Dense(128, activation='relu')) # The numbers are mostly in the powers of 2\n",
        "model.add(keras.layers.Dropout(0.5)) # Dropout randomly deactivates 50% of the neurons during training, Prevents overfitting by making the network less dependent on specific neurons.\n",
        "\n",
        "model.add(keras.layers.Dense(64, activation='relu')) # same as above\n",
        "model.add(keras.layers.Dropout(0.5))\n",
        "\n",
        "model.add(keras.layers.Dense(num_of_classes, activation='sigmoid')) # output layer, sigmoid gives a probability between 0 and 1.\n",
        "#(sigmoid because it is used in binary classification, there is also smthng called as softmax it is used when the prblm is of multi class classification(more than 2, ours is binary))\n",
        "#(why? num_of_classes(because it depicts how many neurons, in our case it will be 2 which tells that 1 neuron will give prob. of with mask and other of without mask))"
      ],
      "metadata": {
        "id": "KTrPZ8DPskL7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# compile the neural network\n",
        "model.compile(optimizer='adam',\n",
        "              loss='sparse_categorical_crossentropy',\n",
        "              metrics=['acc'])\n",
        "# Optimizer- It determines how the network will be updated based on the loss function.\n",
        "# Loss- It is also known as loss function it basically compute errors between the predicted output and actual output.\n",
        "# The sparse categorical cross-entropy loss function works by first converting the true labels into one-hot encoded vectors internally and then applying the regular categorical cross-entropy loss calculation.\n",
        "# metrics- A metric is a function that is used to judge the performance of your model."
      ],
      "metadata": {
        "id": "81BWgta2s5hI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# training our neural network\n",
        "history=model.fit(X_train_scaled, Y_train, validation_split=0.1, epochs=5)\n",
        "#validation split- How your model is performing on unknown data on each epoch(in overfitting the training accuracy will be high but your validation accuracy will be low)"
      ],
      "metadata": {
        "id": "uJs1glGmw4gQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Model Evaluation**"
      ],
      "metadata": {
        "id": "7mlQvTtAyK1P"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "loss, accuracy = model.evaluate(X_test_scaled, Y_test)\n",
        "print('Test Accuracy=', accuracy)\n",
        "#It runs the model on test data and it returns accuracy and loss"
      ],
      "metadata": {
        "id": "AaG4BtwzxMlt",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "h=history\n",
        "\n",
        "# plot the loss value\n",
        "plt.plot(h.history['loss'], label='train loss')\n",
        "plt.plot(h.history['val_loss'], label='validation loss')\n",
        "plt.legend()\n",
        "plt.show()\n",
        "\n",
        "# plot the accuracy value\n",
        "plt.plot(h.history['acc'], label='accuracy')\n",
        "plt.plot(h.history['val_acc'], label='validation accuracy')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "KZa_9is3yZov"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Predictive System**"
      ],
      "metadata": {
        "id": "6NzXIRxrzT5E"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#input image will need to be added\n",
        "input_image_path=input('Path of the image to be predicted')\n",
        "input_image=cv2.imread(input_image_path) # to read the image given by the user and convert it to a numpy array\n",
        "\n",
        "cv2_imshow(input_image)\n",
        "\n",
        "input_image_resize= cv2.resize(input_image, (128,128)) # to resize the image\n",
        "\n",
        "input_image_scaled= input_image_resize/255 # to make it the value between 0 or 1\n",
        "\n",
        "input_reshape= input_image_scaled.reshape(1,128,128,3) # this line tells the program that we are making prediction for 1 data point\n",
        "\n",
        "input_prediction=model.predict(input_reshape) # it is used to make a prediction using the reshaped data\n",
        "\n",
        "print(input_prediction) # The output will be a probability not a 0 or 1 like machine learning\n",
        "\n",
        "input_pred_label= np.argmax(input_prediction) # If the first value is maximum it will return 0 else it will return 1. This step is done to convert probability values to specific labels\n",
        "\n",
        "print(input_pred_label)\n",
        "\n",
        "if input_pred_label == 1:\n",
        "  print('The person in the image is wearing a mask')\n",
        "else:\n",
        "  print('The person in the image is not wearing a mask')"
      ],
      "metadata": {
        "id": "PmFtBTy7zCsb"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}